{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/truongtaoday/train/blob/main/SDVN_TrainingSDXL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX7ARqPuAYzA"
      },
      "source": [
        "# [![](https://img.shields.io/badge/Thi·∫øt%20k·∫ø-stablediffusion.vn-0075ff)](https://stablediffusion.vn) [![](https://img.shields.io/badge/Phi√™n%20b·∫£n-v3-0075ff)](https://stablediffusion.vn) [![](https://img.shields.io/badge/Legacy-Version-ff0000)](https://bit.ly/trainsdxl) [![](https://img.shields.io/badge/Group-Support-0075ff)](https://www.facebook.com/groups/stablediffusion.vn) [![](https://img.shields.io/badge/B·ªô%20c√¥ng%20c·ª•-ƒê·∫ßy%20ƒë·ªß-0075ff)](https://stablediffusion.vn/bo-cong-cu/) [![](https://img.shields.io/discord/813085864355037235?color=blue&label=Discord&logo=Discord)](https://discord.gg/5SEtApPeyG) [![](https://img.shields.io/badge/Kohya%20Setting-Wiki-Blue)](https://github.com/bmaltais/kohya_ss/wiki/LoRA-training-parameters) [![](https://img.shields.io/badge/Kho√°%20h·ªçc-SD-red)](https://hungdiffusion.com/)\n",
        "\n",
        "---\n",
        "# üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng :\n",
        "\n",
        "\n",
        " - B1 : Chu·∫©n b·ªã th∆∞ m·ª•c ·∫£nh m·∫´u ƒë·ªÉ train theo ƒë√∫ng k√≠ch th∆∞·ªõc, t·∫£i l√™n drive, c√≥ th·ªÉ ph√¢n chia th∆∞ m·ª•c con\n",
        " - B1 : Ch·∫°y ph·∫ßn 1\n",
        " - B2 : Ch·ªânh Path ƒë·ªÉ d·∫´n ƒë·∫øn th∆∞ m·ª•c data ƒë√£ t·∫£i v√† ch·∫°y ph·∫ßn 2\n",
        " - B3 : Ch·ªânh c√°c th√¥ng s·ªë train t·∫°i m·ª•c 3 v√† ch·∫°y ph·∫ßn 3\n",
        " - B4 : Ch·∫°y m·ª•c 4 v√† theo d√µi k·∫øt qu·∫£ train\n",
        " ---\n",
        "\n",
        " üîª : L∆∞u √Ω quan tr·ªçng thay ƒë·ªïi theo m·ªói l·∫ßn train\n",
        "\n",
        " üî∏ : Gi√° tr·ªã tham kh·∫£o, c√≥ th·ªÉ ƒë·ªÉ m·∫∑c ƒë·ªãnh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOYanXQ4REKA"
      },
      "source": [
        "# üîå 1. C√†i ƒë·∫∑t n·ªÅn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_u3q60di584x"
      },
      "outputs": [],
      "source": [
        "# @title Install\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root_dir = \"/content\"\n",
        "repo_dir = f\"{root_dir}/Kohya-Colab\"\n",
        "training_dir = f\"{root_dir}/Train_Config\"\n",
        "pretrained_model = f\"{root_dir}/Train_model\"\n",
        "config_dir = f\"{training_dir}/Config\"\n",
        "\n",
        "accelerate_config = f\"{repo_dir}/accelerate_config/config.yaml\"\n",
        "tools_dir = f\"{repo_dir}/tools\"\n",
        "finetune_dir = f\"{repo_dir}/finetune\"\n",
        "\n",
        "!git clone https://github.com/StableDiffusionVN/SDVN-kohya-colab-sdxl {repo_dir}\n",
        "\n",
        "%run {repo_dir}/TrainScript.ipynb\n",
        "\n",
        "install_sdxl()\n",
        "\n",
        "aria_down(\"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",pretrained_model,\"sdxl_vae.safetensors\")\n",
        "vae_path = f\"{pretrained_model}/sdxl_vae.safetensors\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA8Uom4hQ_8e"
      },
      "source": [
        "# üìÇ 2. K·∫øt n·ªëi data Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iyH80EFGKrj4"
      },
      "outputs": [],
      "source": [
        "#@markdown ##<br>üîª 2.1 ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c d·ªØ li·ªáu trong drive\n",
        "\n",
        "#@markdown <br>üí° `C√≥ th·ªÉ b·ªè tr·ªëng RegFolder`\n",
        "TrainFolder = \"/content/drive/MyDrive/SD-Data/TrainData\"  # @param {type:'string'}\n",
        "DataClean = False #@param {type:\"boolean\"}\n",
        "Merge_metadata = True #@param {type:\"boolean\"}\n",
        "SubFolder = True\n",
        "#@markdown ##<br>üî∏ 2.2 T·∫°o caption t·ª± ƒë·ªông\n",
        "AutoCaption = \"All\" # @param [\"none\", \"All\", \"BLIP-Caption\", \"Waifu-1.4\"]\n",
        "Caption_Length = \"Medium\" # @param ['Short','Medium','Long']\n",
        "\n",
        "# @markdown üü° `Th√™m caption tu·ª≥ ch·ªçn`\n",
        "Custom_Caption = \"\" # @param {type:'string',placeholder:\"Nh·∫≠p t·ª´ kho√° tu·ª≥ ch·ªçn ho·∫∑c chu·ªói mu·ªën xo√° khi ch·ªçn ch·∫ø ƒë·ªô Remove\"}\n",
        "Remove_Caption = False #@param {type:\"boolean\"}\n",
        "Append = False\n",
        "# @markdown üü° `T·ª± ƒë·ªông nh·∫≠n t√™n th∆∞ m·ª•c con l√†m caption`\n",
        "AddFolderName = False #@param {type:\"boolean\"}\n",
        "SubFolder = True\n",
        "\n",
        "extension = \".txt\"\n",
        "\n",
        "Cap_prompt = {\n",
        "    'Short':['<CAPTION>',10,30,0.8],\n",
        "    'Medium':['<DETAILED_CAPTION>',10,100,0.5],\n",
        "    'Long':['<MORE_DETAILED_CAPTION>',10,150,0.3]\n",
        "}\n",
        "\n",
        "if DataClean == True :\n",
        "    %cd {root_dir}\n",
        "    clean_directory(TrainFolder)\n",
        "\n",
        "if AutoCaption in [\"Waifu-1.4\",\"All\"] :\n",
        "    %cd {finetune_dir}\n",
        "    config = {\n",
        "        \"_train_data_dir\": TrainFolder,\n",
        "        \"batch_size\": 6,\n",
        "        \"repo_id\": \"SmilingWolf/wd-v1-4-convnext-tagger-v2\",\n",
        "        \"recursive\": True,\n",
        "        \"remove_underscore\": True,\n",
        "        \"general_threshold\": Cap_prompt[Caption_Length][3],\n",
        "        \"character_threshold\": 0.2,\n",
        "        \"caption_extension\": \".txt\",\n",
        "        \"max_data_loader_n_workers\": 2,\n",
        "        \"debug\": True,\n",
        "        \"undesired_tags\": \"\"\n",
        "    }\n",
        "    final_args = f\"python {finetune_dir}/tag_images_by_wd14_tagger.py {join_arg(config)}\"\n",
        "    print(final_args)\n",
        "    !{final_args}\n",
        "\n",
        "if AutoCaption in [\"BLIP-Caption\",\"All\"] :\n",
        "    %cd {finetune_dir}\n",
        "    config = {\n",
        "        \"_train_data_dir\" : TrainFolder,\n",
        "        \"batch_size\" : 6,\n",
        "        \"beam_search\" : True,\n",
        "        \"min_length\" : Cap_prompt[Caption_Length][1],\n",
        "        \"max_length\" : Cap_prompt[Caption_Length][2],\n",
        "        \"debug\" : True,\n",
        "        \"caption_extension\" : \".caption\",\n",
        "        \"max_data_loader_n_workers\" : 2,\n",
        "        \"recursive\" : True\n",
        "    }\n",
        "    final_args = f\"python {finetune_dir}/make_captions.py {join_arg(config)}\"\n",
        "    print(final_args)\n",
        "    !{final_args}\n",
        "\n",
        "if AddFolderName:\n",
        "  add_forder_name(TrainFolder)\n",
        "if Custom_Caption != \"\":\n",
        "  process_dir(TrainFolder, Custom_Caption, Append, Remove_Caption)\n",
        "\n",
        "#bucketing\n",
        "\n",
        "bucketing_json    = f\"{training_dir}/meta_lat.json\"\n",
        "metadata_json     = f\"{training_dir}/meta_clean.json\"\n",
        "\n",
        "metadata_config = {\n",
        "    \"_train_data_dir\": TrainFolder,\n",
        "    \"_out_json\": metadata_json,\n",
        "    \"recursive\": True,\n",
        "    \"full_path\": True,\n",
        "    \"clean_caption\": False\n",
        "}\n",
        "\n",
        "bucketing_config = {\n",
        "    \"_train_data_dir\": TrainFolder,\n",
        "    \"_in_json\": metadata_json,\n",
        "    \"_out_json\": bucketing_json,\n",
        "    \"_model_name_or_path\": vae_path,\n",
        "    \"recursive\": True,\n",
        "    \"full_path\": True,\n",
        "    \"flip_aug\": False,\n",
        "    \"skip_existing\": False,\n",
        "    \"batch_size\": 4,\n",
        "    \"max_data_loader_n_workers\": 2,\n",
        "    \"max_resolution\": f\"{1024}, {1024}\",\n",
        "    \"mixed_precision\": \"no\",\n",
        "}\n",
        "\n",
        "if Merge_metadata == True :\n",
        "  %cd {finetune_dir}\n",
        "  merge_metadata_args = join_arg(metadata_config)\n",
        "  prepare_buckets_args = join_arg(bucketing_config)\n",
        "  merge_metadata_command = f\"python merge_all_to_metadata.py {merge_metadata_args}\"\n",
        "  prepare_buckets_command = f\"python prepare_buckets_latents.py {prepare_buckets_args}\"\n",
        "  !{merge_metadata_command}\n",
        "  !{prepare_buckets_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZVkLuaRJ9e"
      },
      "source": [
        "# ‚öôÔ∏è 3. C√†i ƒë·∫∑t Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qN_dahzDj2fl"
      },
      "outputs": [],
      "source": [
        "#@markdown ##üîª 3.1 C√†i ƒë·∫∑t chung\n",
        "#@markdown <br>\n",
        "Train_Option = \"Lora\" # @param [\"Checkpoint\",\"Lora\"]\n",
        "Project_name = \"\" #@param {type:\"string\",placeholder:\"Nh·∫≠p t√™n output\"}\n",
        "Output_Path = \"/content/drive/MyDrive/SD-Data\" # @param {type:\"string\"}\n",
        "#@markdown <br>üí° `D√°n link t·∫£i ho·∫∑c link ƒë∆∞·ªùng d·∫´n drive ƒë·ªÉ s·ª≠ d·ª•ng model b·∫•t k·ª≥ ƒë·ªÉ train`\n",
        "Model_Train = \"\"  #@param [\"\",\"SDXL-Base\", \"XXMix_9realisticSDXL\", \"LEOSAM-HelloWorldXL\", \"AdamXL-v3\", \"JuggernautXL-v9\", \"ZavyChromaXL-v5\", \"Samaritan3dCartoon-v4\", \"DucHaiten-AIart-SDXL\", \"JuggernautXL\"] {allow-input: true}\n",
        "Resume_Path = \"\" # @param {type:'string',placeholder:\"Nh·∫≠p t√™n ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c State n·∫øu mu·ªën train ti·∫øp t·ª´ backup\"}\n",
        "Save_State = False #@param {type:\"boolean\"}\n",
        "Resolution = \"1024,1024\" # @param {type:'string'}\n",
        "Batch_size = 1  # @param {type:\"number\"}\n",
        "Repeats = 10  # @param {type:\"number\"}\n",
        "Lr_scheduler = \"constant_with_warmup\" # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n",
        "#@markdown ##<br>üîª 3.2-A | Checkpoint Setting\n",
        "#@markdown <br>\n",
        "Ckpt_Lr  = 1e-6  # @param {'type':'number'}\n",
        "Max_train_steps = 10000  # @param {type:\"number\"}\n",
        "Save_Every_N_Steps = 1000  # @param {type:\"number\"}\n",
        "Train_text_encoder = False  # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ##<br>üîª 3.2-B | Lora Setting\n",
        "LoRA_Network_Weights = \"\" # @param {'type':'string'}\n",
        "Network_dim = 32  # @param {'type':'number'}\n",
        "Network_alpha = 16 # @param {'type':'number'}\n",
        "Lora_Lr = 1e-4  # @param {'type':'number'}\n",
        "Epochs = 4  # @param {type:\"number\"}\n",
        "Save_Every_N_Epochs = 1  # @param {type:\"number\"}\n",
        "Comment = \"creator by sdvn.me\" # @param {'type':'string'}\n",
        "\n",
        "output_name = Project_name if Project_name != \"\" else \"project_name\"\n",
        "output_dir = f'{Output_Path}/{\"Lora\" if Train_Option == \"Lora\" else \"Model\"}'\n",
        "file_path = f'{repo_dir}/model_lib.json'\n",
        "with open(file_path, 'r') as json_file:\n",
        "    modellist = json.load(json_file)\n",
        "pretrained_model_name_or_path = download_lib(Model_Train,modellist,pretrained_model)\n",
        "\n",
        "resume = Resume_Path\n",
        "save_state = Save_State\n",
        "resolution = Resolution\n",
        "train_batch_size = Batch_size\n",
        "dataset_repeats = Repeats\n",
        "lr_scheduler = Lr_scheduler\n",
        "learning_rate = Ckpt_Lr if Train_Option == \"Checkpoint\" else Lora_Lr\n",
        "max_train_steps = Max_train_steps if Train_Option == \"Checkpoint\" else None\n",
        "save_every_n_steps = Save_Every_N_Steps if Train_Option == \"Checkpoint\" else None\n",
        "train_text_encoder = Train_text_encoder\n",
        "network_weights = LoRA_Network_Weights\n",
        "network_dim = Network_dim\n",
        "network_alpha = Network_alpha\n",
        "max_train_epochs = Epochs\n",
        "save_every_n_epochs = Save_Every_N_Epochs\n",
        "training_comment = Comment\n",
        "with open(f'{training_dir}/meta_clean.json', 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "prompt = list(data.values())[0][\"tags\"]\n",
        "sampler_prompt = f\"{prompt}, best quality\"\n",
        "subset = [{\"prompt\": sampler_prompt}]\n",
        "%cd {root_dir}\n",
        "\n",
        "sample_file   = f\"{config_dir}/sample_prompt.toml\"\n",
        "config_file     = f\"{config_dir}/config_file.toml\"\n",
        "\n",
        "default_config_lora = f\"{repo_dir}/config/default_config_lora.json\"\n",
        "default_config_checkpoint = f\"{repo_dir}/config/default_config_checkpoint.json\"\n",
        "default_config_sampler = f\"{repo_dir}/config/default_config_sampler.json\"\n",
        "\n",
        "final_config(default_config_lora if Train_Option == \"Lora\" else default_config_checkpoint,config_file)\n",
        "final_config(default_config_sampler,sample_file)\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD3clKOM5x6P"
      },
      "source": [
        "# ‚åõÔ∏è 4. Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p_SHtbFwHVl1"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "#@markdown #‚ñ∂Ô∏è Theo d√µi qu√° tr√¨nh v√† ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng\n",
        "#@markdown *Ki·ªÉm tra sample t·∫°i ```{Output_Path}/sample```*\n",
        "#@markdown <br>*C√≥ th·ªÉ d·ª´ng b·∫•t c·ª© khi n√†o sample th·∫•y ∆∞ng √Ω*\n",
        "AutoDisconect = False #@param {type:\"boolean\"}\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : accelerate_config,\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\"  : sample_file,\n",
        "    \"config_file\"     : config_file\n",
        "}\n",
        "\n",
        "accelerate_args = join_arg(accelerate_conf)\n",
        "train_args = join_arg(train_conf)\n",
        "Train_File = \"sdxl_train_network.py\" if Train_Option == \"Lora\" else \"sdxl_train.py\"\n",
        "\n",
        "final_args = f\"accelerate launch {accelerate_args} {Train_File} {train_args}\"\n",
        "!{final_args}\n",
        "if AutoDisconect:\n",
        "    from time import sleep\n",
        "    sleep(180)\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TOYanXQ4REKA",
        "6mdkmCHajqaT",
        "t4ONHYyok9Y2",
        "dgnXdh0ICTnn"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}